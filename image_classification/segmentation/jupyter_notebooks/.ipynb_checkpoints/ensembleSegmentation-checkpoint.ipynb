{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d77b9a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry import Polygon\n",
    "from PIL import ImageDraw as draw\n",
    "import json\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import pickle\n",
    "random.seed(41)\n",
    "import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2f0b570a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_iou_from_contours(poly1, poly2) -> float:\n",
    "    \"\"\"\n",
    "    Get the Intersection-over-Union value between two contours.\n",
    "    :param poly1: The first contour used to compute the\n",
    "                  Intersection-over-Union.\n",
    "    :param poly2: The second contour used to compute the\n",
    "                  Intersection-over-Union.\n",
    "    :return: The computed Intersection-over-Union value between the two\n",
    "             contours.\n",
    "    \"\"\"\n",
    "    if not poly1 or not poly2:\n",
    "        return -1\n",
    "    intersection = poly1.intersection(poly2).area\n",
    "    union = poly1.area + poly2.area - intersection\n",
    "    return intersection / union if union != 0 else 1\n",
    "\n",
    "def read_cc_based(path, t=0.01):\n",
    "    \"\"\"\n",
    "        path: json path to the stored boxes coors\n",
    "        t:    the threshold to filter out small boxes\n",
    "    \"\"\"\n",
    "    boxes = json.load(open(path))\n",
    "    \n",
    "    # read the image to get the size of images, no need to read the img again if you have it already!\n",
    "    img = Image.open(path.replace(\".json\", \".jpg\"))\n",
    "    h, w = img.size\n",
    "    full_area = h*w\n",
    "    \n",
    "    filter_boxes = []\n",
    "    for box in boxes:\n",
    "        poly = Polygon(box)\n",
    "        if poly.area / full_area > t:\n",
    "            filter_boxes.append(box)\n",
    "    return filter_boxes\n",
    "    \n",
    "def read_peak_based(path, t=0.12, viz=False):\n",
    "    \n",
    "    # read the image to get the size of images, no need to read the img again if you have it already!\n",
    "    img = Image.open(\"/trunk/shared/cuneiform/full_data/images/\" + path.replace(\".json\", \".jpg\").split('/')[-1])\n",
    "    h, w = img.size\n",
    "\n",
    "    res = json.load(open(path))\n",
    "    \n",
    "    # the split points (either vertical or horizontal)\n",
    "    # so these lines segment the orginal images into different regions\n",
    "    splits =  {\n",
    "        \"v_split\": [0] + sorted(res['col_res']) + [h], \n",
    "        \"h_split\": [0] + sorted(res['row_res']) + [w]\n",
    "    }\n",
    "    # print(splits)\n",
    "    boxes = []\n",
    "    max_v = 0\n",
    "    for i in range(1, len(splits['v_split'])):\n",
    "        for j in range(1, len(splits['h_split'])):\n",
    "            x0 = splits['v_split'][i - 1]\n",
    "            y0 = splits['h_split'][j - 1]\n",
    "            x1 = splits['v_split'][i]\n",
    "            y1 = splits['h_split'][j]\n",
    "            # print((x0, y0, x1, y1))\n",
    "            patch = img.crop((x0, y0, x1, y1))\n",
    "            # display(patch)\n",
    "            mean_v =  np.array(patch).mean()\n",
    "            boxes.append([(x0, y0, x1, y1), mean_v])\n",
    "            # \n",
    "            if mean_v > max_v:\n",
    "                max_v = mean_v\n",
    "            # print(np.array(patch).mean())\n",
    "            \n",
    "    # filter those empty box by the mean_v\n",
    "\n",
    "    filter_boxes = []\n",
    "    for b, v in boxes:\n",
    "        if v > max_v * t:\n",
    "            if viz:\n",
    "                display(img.crop(b))\n",
    "            filter_boxes.append(b)\n",
    "    return filter_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ac0b0a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_front_polygon(example):\n",
    "    areas = {}\n",
    "    for idx, coords in enumerate(example):\n",
    "        polygon = Polygon(coords)\n",
    "        areas[idx] = polygon.area\n",
    "    areas = dict(sorted(areas.items(), key=lambda item: item[1], reverse=True))\n",
    "    if(len(areas)==1):\n",
    "        return example[0]\n",
    "    top_two_polygons = (example[list(areas.keys())[0]], example[list(areas.keys())[1]])\n",
    "\n",
    "    min_y = float('inf')\n",
    "    front_poly_idx = -1\n",
    "    for idx, poly in enumerate(top_two_polygons):\n",
    "        for coord in poly:\n",
    "            if min_y > coord[1]:\n",
    "                min_y = coord[1]\n",
    "                front_poly_idx = idx\n",
    "    return top_two_polygons[front_poly_idx]\n",
    "\n",
    "def getFrontCutoutForSA(masks):\n",
    "    frontMask = None\n",
    "    if len(masks) == 0:\n",
    "        return frontMask\n",
    "    elif len(masks) == 1:\n",
    "        frontMask = masks[0]['bbox']\n",
    "    elif len(masks) > 2:\n",
    "        if masks[0]['bbox'][0] <=5 and masks[0]['bbox'][1] <=5:\n",
    "            #masks[0] is background, choose from 1 or 2\n",
    "            if masks[1]['area'] > masks[2]['area']*1.5: #masks[1] is much bigger than masks[2]\n",
    "                frontMask = masks[1]['bbox']\n",
    "            elif masks[1]['bbox'][1] < masks[2]['bbox'][1]:  # ycoordinate of front mask will be smaller\n",
    "                frontMask = masks[1]['bbox']\n",
    "            else:\n",
    "                frontMask = masks[2]['bbox']\n",
    "        else:\n",
    "            frontMask = masks[0]['bbox']\n",
    "    else:\n",
    "        if masks[0]['bbox'][0] <=5 and masks[0]['bbox'][1] <=5:\n",
    "            frontMask = masks[1]['bbox']\n",
    "        else:\n",
    "            frontMask = masks[0]['bbox']\n",
    "            \n",
    "    return frontMask\n",
    "\n",
    "def convert_peak_to_coords(peak_example):\n",
    "    coords_example = []\n",
    "    for coords in peak_example:\n",
    "        x_0 = coords[0]\n",
    "        y_0 = coords[1]\n",
    "        x_1 = coords[2]\n",
    "        y_1 = coords[3]\n",
    "        curr = [[x_0,y_0],[x_0,y_1],[x_1,y_1],[x_1,y_0]]\n",
    "        coords_example.append(curr)\n",
    "    return coords_example\n",
    "        \n",
    "def convert_sa_to_coords(sa_front):\n",
    "    x,y,w,h = sa_front\n",
    "    return [[x,y],[x+w,y],[x+w,y+h],[x,y+h]]\n",
    "\n",
    "def resizeCCExample(cc_example):\n",
    "    cc_np = np.array(cc_example)\n",
    "    while np.any(cc_np>2000):\n",
    "        cc_np = cc_np/2\n",
    "    return cc_np.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "73087099",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of images with bad segmentation 9742\n",
      "Total images for which IoU is checked 56694\n",
      "Remaining images to check 0\n"
     ]
    }
   ],
   "source": [
    "with open('/trunk/shared/cuneiform/CuneiformDating/image_classification/segmentation/code/temp_results/run_segmentation_again.json', 'r') as f:\n",
    "    bad_ids = json.load(f)\n",
    "\n",
    "#sample 200 random images\n",
    "# sampled_pids = random.sample(all_ids,200)\n",
    "print(\"No of images with bad segmentation\", len(bad_ids))\n",
    "\n",
    "with open('/trunk/shared/cuneiform/full_data/all_ids.json', 'r') as f:\n",
    "    all_ids = json.load(f)\n",
    "\n",
    "with open('/trunk/shared/cuneiform/CuneiformDating/image_classification/segmentation/code/temp_results/iou_segmentation.json', 'r') as f:\n",
    "    iou_info = json.load(f)\n",
    "    \n",
    "print(\"Total images for which IoU is checked\", len(iou_info.keys()))\n",
    "\n",
    "\n",
    "remaining_imgs = list(set(all_ids) - set(iou_info.keys()))\n",
    "print(\"Remaining images to check\", len(list(remaining_imgs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b6edc273",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "still_bad_ids = []\n",
    "for idx, pid in tqdm.tqdm(enumerate(bad_ids)):\n",
    "    cc_path = \"/trunk2/datasets/cuneiform/segmentation/seg_viz_July05/P\" + str(pid).zfill(6)+ \".json\"\n",
    "    if os.path.exists(cc_path):\n",
    "        cc_example = read_cc_based(cc_path)\n",
    "        cc_example = resizeCCExample(cc_example)\n",
    "        cc_front = get_front_polygon(cc_example)\n",
    "        poly_cc = Polygon(cc_front)\n",
    "    else:\n",
    "        poly_cc = None\n",
    "\n",
    "    peak_path=\"/trunk2/datasets/cuneiform/segmentation/seg_peak_base_July06/P\" + str(pid).zfill(6)+ \".json\"\n",
    "    if os.path.exists(peak_path):\n",
    "        peak_example = read_peak_based(peak_path)\n",
    "        peak_front = get_front_polygon(convert_peak_to_coords(peak_example))\n",
    "        poly_peak = Polygon(peak_front)\n",
    "    else:\n",
    "        poly_peak = None\n",
    "\n",
    "\n",
    "    segmentAnything_path = \"/trunk/shared/cuneiform/full_data/segmented_mask_info_compressed/P\" + str(pid).zfill(6)+ \".pkl\"\n",
    "    if os.path.exists(segmentAnything_path):\n",
    "        with open(segmentAnything_path, 'rb') as f:\n",
    "            all_masks = pickle.load(f)\n",
    "\n",
    "        sa_front = getFrontCutoutForSA(all_masks)\n",
    "        sa_front = convert_sa_to_coords(sa_front)\n",
    "        poly_sa = Polygon(sa_front)\n",
    "    else:\n",
    "        poly_sa = None\n",
    "\n",
    "    iou_sa_cc = compute_iou_from_contours(poly_cc,poly_sa)\n",
    "    iou_sa_peak = compute_iou_from_contours(poly_peak,poly_sa)\n",
    "    iou_peak_cc = compute_iou_from_contours(poly_cc,poly_peak)\n",
    "\n",
    "    if max(iou_sa_cc, iou_sa_peak) < 0.79:\n",
    "        still_bad_ids.append(pid)\n",
    "    iou_info[pid] = {\"iou_sa_cc\":iou_sa_cc, \"iou_sa_peak\":iou_sa_peak, \"iou_peak_cc\":iou_peak_cc}\n",
    "    if idx%1000==0 or idx == len(bad_ids)-1:\n",
    "        with open(\"/trunk/shared/cuneiform/CuneiformDating/image_classification/segmentation/code/temp_results/iou_segmentation.json\", \"w\") as f:\n",
    "            json.dump(iou_info,f)\n",
    "        with open(\"/trunk/shared/cuneiform/CuneiformDating/image_classification/segmentation/code/temp_results/still_bad_ids.json\", \"w\") as f:\n",
    "            json.dump(still_bad_ids, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "04c3d648",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47607"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(iou_info.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "75db7115",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([[486.5, 692.5], [482.5, 280.0], [843.5, 276.5], [847.75, 689.0]],\n",
       " [[464, 199], [464, 713], [858, 713], [858, 199]],\n",
       " [[482, 63], [846, 63], [846, 691], [482, 691]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc_front, peak_front, sa_front"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5ebaf4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
